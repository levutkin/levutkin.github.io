% Encoding: x-MacCyrillic

@ARTICLE{Angulo-etal-2008,
  author = {C. Angulo and D. Anguita and L. Gonzalez-Abrilc and J.A. Ortega},
  title = {Support vector machines for interval discriminant analysis},
  journal = {Neurocomputing},
  year = {2008},
  volume = {71},
  pages = {1220-1229},
  number = {7-9},
  owner = {lev u},
  timestamp = {2016.05.01}
}

@INPROCEEDINGS{Antonucci-2014,
  author = {A. Antonucci and R. de Rosa and A. Giusti and F. Cuzzolin},
  title = {Temporal data classification by imprecise dynamical models},
  booktitle = {Proc. of the 8th International Symposium on Imprecise Probability:
	Theories and Applications},
  year = {2013},
  pages = {13-22},
  address = {Compiegne, France},
  publisher = {SIPTA},
  owner = {LVU},
  timestamp = {2015.01.14}
}

@INPROCEEDINGS{Barreiros-et-al-2015,
  author = {D.B. Barreiros and M.A.O. Domingues and R.M.C.R. Souza and F.J.A.
	Cysneiros},
  title = {An Interval Expectation Maximization Algorithm for Outlier Detection
	in Linear Regression},
  booktitle = {Proceedings of the International Conference on Artificial Intelligence
	(ICAI)},
  year = {2015},
  pages = {599--603},
  address = {Athens},
  publisher = {The Steering Committee of The World Congress in Computer Science,
	Computer Engineering and Applied Computing (WorldComp)},
  owner = {lev u},
  timestamp = {2016.09.06}
}

@ARTICLE{Beaumont-1998,
  author = {O. Beaumont},
  title = {Solving interval linear systems with linear programming techniques},
  journal = {Linear Algebra and Its Applications},
  year = {1998},
  volume = {281},
  pages = {293-309},
  owner = {LVU},
  timestamp = {2014.09.19}
}

@Article{Ben-Tal-2011,
  author    = {A. Ben-Tal and S. Bhadra and C. Bhattacharyya and J.S. Nath},
  title     = {Chance constrained uncertain classification via robust optimization},
  journal   = {Mathematical Programming, Series B},
  year      = {2011},
  volume    = {127},
  number    = {1},
  pages     = {145-173},
  comment   = {This paper studies the problem of constructing robust classifiers
	when the training is plagued with uncertainty. The problem is posed
	as a Chance-Constrained Program (CCP) which ensures that the uncertain
	data points are classified correctly with high probability. Unfortunately
	such a CCP turns out to be intractable. The key novelty is in employing
	Bernstein bounding schemes to relax the CCP as a convex second order
	cone program whose solution is guaranteed to satisfy the probabilistic
	constraint. Prior to this work, only the Chebyshev based relaxations
	were exploited in learning algorithms. Bernstein bounds employ richer
	partial information and hence can be far less conservative than Chebyshev
	bounds. Due to this efficient modeling of uncertainty, the resulting
	classifiers achieve higher classification margins and hence better
	generalization. Methodologies for classifying uncertain test data
	points and error measures for evaluating classifiers robust to uncertain
	data are discussed. Experimental results on synthetic and real-world
	datasets show that the proposed classifiers are better equipped to
	handle data uncertainty and outperform state-of-the-art in many cases.},
  owner     = {lev u},
  timestamp = {2015.09.26},
}

@INCOLLECTION{Bhadra-2009,
  author = {S. Bhadra and J.S. Nath and A. Ben-Tal and C. Bhattacharyya},
  title = {Interval data classification under partial information: A chance-constraint
	approach},
  booktitle = {Advances in Knowledge Discovery and Data Mining},
  publisher = {Springer},
  year = {2009},
  editor = {T. Theeramunkong and B. Kijsirikul and N. Cercone and T.-B. Ho},
  volume = {5476},
  series = {Lecture Notes in Computer Science},
  pages = {208-219},
  address = {Berlin Heidelberg},
  doi = {10.1007/978-3-642-01307-2_21},
  isbn = {978-3-642-01306-5},
  language = {English},
  owner = {LVU},
  timestamp = {2014.09.28}
}

@ARTICLE{Billard-2008,
  author = {L. Billard},
  title = {Some analyses of interval data},
  journal = {Journal of Computing and Information Technology},
  year = {2008},
  volume = {16},
  pages = {225-233},
  number = {4}
}

@BOOK{Billard-Diday-2006,
  title = {Symbolic Data Analysis: Conceptual Statistics and Data Mining},
  publisher = {John Wiley \& Sons},
  year = {2006},
  author = {L. Billard and E. Diday},
  owner = {lev u},
  timestamp = {2015.10.31}
}

@INPROCEEDINGS{Billard-Diday-2000,
  author = {L. Billard and E. Diday},
  title = {Regression analysis for interval-valued data},
  booktitle = {Data Analysis, Classification and Related Methods: Proceedings of
	the Seventh Conference of the International Federation of Classification
	Societies},
  year = {2000},
  pages = {369-374},
  publisher = {Springer-Verlag},
  owner = {lev u},
  timestamp = {2015.10.31}
}

@ARTICLE{Boggs-Tolle-1995,
  author = {P.T. Boggs and J.W. Tolle},
  title = {Sequential quadratic programming},
  journal = {Acta numerica},
  year = {1995},
  volume = {4},
  pages = {1-51},
  owner = {LVU},
  timestamp = {2014.10.12}
}

@TECHREPORT{Carrizosa-Gordillo-Plastria07,
  author = {E. Carrizosa and J. Gordillo and F. Plastria},
  title = {Classification problems with imprecise data through separating hyperplanes},
  institution = {MOSI Department, Vrije Universiteit Brussel},
  year = {2007},
  number = {MOSI/33},
  month = {September},
  owner = {LVU},
  timestamp = {2010.12.11}
}

@TECHREPORT{Carrizosa-Gordillo-Plastria07a,
  author = {E. Carrizosa and J. Gordillo and F. Plastria},
  title = {Support Vector Regression for imprecise data},
  institution = {MOSI Department, Vrije Universiteit Brussel},
  year = {2007},
  number = {MOSI/35},
  month = {October},
  owner = {LVU},
  timestamp = {2010.12.11}
}

@ARTICLE{Carvalho-2016,
  author = {F.de A.T.de Carvalho and P. Bertrand and E.C. Simoes},
  title = {Batch {SOM} algorithms for interval-valued data with automatic weighting
	of the variables},
  journal = {Neurocomputing},
  year = {2016},
  volume = {182},
  pages = {66-81},
  owner = {lev u},
  timestamp = {2016.05.08}
}

@ARTICLE{Carvalho-Lechevallier-2009,
  author = {F.de A.T. de Carvalho and Y. Lechevallier},
  title = {Dynamic clustering of interval-valued data based on adaptive quadratic
	distances},
  journal = {IEEE Transactions on Sytems, Man and Cybernetics - Part A: Systems
	and Humans},
  year = {2009},
  volume = {39},
  pages = {1295-1306},
  number = {6},
  owner = {lev u},
  timestamp = {2016.08.20}
}

@ARTICLE{Carvalho-Lechevallier-2009a,
  author = {F.de A.T. de Carvalho and Y. Lechevallier},
  title = {Partitional clustering algorithms for symbolic interval data based
	on single adaptive distances},
  journal = {Pattern Recognition},
  year = {2009},
  volume = {42},
  pages = {1223-1236},
  number = {7},
  owner = {lev u},
  timestamp = {2016.08.20}
}

@ARTICLE{Chapelle-2007,
  author = {O. Chapelle},
  title = {Training a support vector machine in the primal},
  journal = {Neural computation},
  year = {2007},
  volume = {19},
  pages = {1155-1178},
  number = {5},
  owner = {lev u},
  timestamp = {2016.05.08}
}

@INCOLLECTION{Chavent-2004,
  author = {M. Chavent},
  title = {A Hausdorff distance between hyper-rectangles for clustering interval
	data},
  booktitle = {Classification, Clustering, and Data Mining Applications},
  publisher = {Springer Berlin Heidelberg},
  year = {2004},
  pages = {333-339},
  owner = {LVU},
  timestamp = {2014.03.15}
}

@ARTICLE{Chavent-2006,
  author = {M. Chavent and F. de A.T. de Carvalho and Y. Lechevallier and R.
	Verde},
  title = {New clustering methods for interval data},
  journal = {Computational statistics},
  year = {2006},
  volume = {21},
  pages = {211-229},
  number = {2},
  owner = {LVU},
  publisher = {Springer-Verlag},
  timestamp = {2014.03.15}
}

@ARTICLE{Chuang-2008,
  author = {Chen-Chia Chuang},
  title = {Extended support vector interval regression networks for interval
	input-output data},
  journal = {Information Sciences},
  year = {2008},
  volume = {178},
  pages = {871-891},
  number = {3},
  doi = {10.1016/j.ins.2007.09.015},
  owner = {LVU},
  timestamp = {2014.03.14}
}

@INPROCEEDINGS{Do-Poulet-2005,
  author = {T.-N. Do and F. Poulet},
  title = {Kernel methods and visualization for interval data mining},
  booktitle = {Internaional Symposium on Applied Stochastic Models and Data Analysis,
	ASMDA},
  year = {2005},
  volume = {5},
  pages = {345-355},
  owner = {LVU},
  timestamp = {2014.03.14}
}

@ARTICLE{Fagundes-2014,
  author = {R.A.A. Fagundes and R.M.C.R. de Souza and F.J.A. Cysneiros},
  title = {Interval kernel regression},
  journal = {Neurocomputing},
  year = {2014},
  volume = {128},
  pages = {371-388},
  owner = {lev u},
  timestamp = {2016.05.01}
}

@INBOOK{Fan-etal-2014,
  pages = {291--305},
  title = {Robust Support Vector Machines with Polyhedral Uncertainty of the
	Input Data},
  publisher = {Springer International Publishing},
  year = {2014},
  author = {N. Fan and E. Sadeghi and P.M. Pardalos},
  address = {Cham},
  booktitle = {Learning and Intelligent Optimization: 8th International Conference}
}

@ARTICLE{Ferecatu-2008,
  author = {M. Ferecatu and N. Boujemaa and M. Crucianu},
  title = {Semantic interactive image retrieval combining visual and conceptual
	content description},
  journal = {ACM Multimedia Systems Journal},
  year = {2008},
  volume = {13},
  pages = {309-322},
  number = {5-6},
  owner = {LVU},
  timestamp = {2014.03.10}
}

@INPROCEEDINGS{Fleuret-Sahbi-03,
  author = {F. Fleuret and H. Sahbi},
  title = {Scale-invariance of support vector machines based on the triangular
	kernel},
  booktitle = {3rd International Workshop on Statistical and Computational Theories
	of Vision},
  year = {2003},
  owner = {LVU},
  timestamp = {2014.03.10}
}

@ARTICLE{Forghani-Yazdi-2014,
  author = {Y. Forghani and H.S. Yazdi},
  title = {Robust support vector machine-trained fuzzy system},
  journal = {Neural Networks},
  year = {2014},
  volume = {50},
  pages = {154-165},
  doi = {10.1016/j.neunet.2013.11.013},
  owner = {LVU},
  timestamp = {2014.03.15}
}

@TECHREPORT{Ghaoui-Lanckriet-Natsoulis-2003,
  author = {L.E. Ghaoui and G.R.G. Lanckriet and G. Natsoulis},
  title = {Robust Classification with Interval Data},
  institution = {University of California},
  year = {2003},
  number = {Report No. UCB/CSD-03-1279},
  address = {Berkeley, California 94720},
  owner = {LVU},
  timestamp = {2012.02.20}
}

@ARTICLE{Gill-Murray-Saunders-2002,
  author = {P.E. Gill and W. Murray and M.A. Saunders},
  title = {{SNOPT}: An {SQP} algorithm for large-scale constrained optimization},
  journal = {SIAM Journal on Optimization},
  year = {2002},
  volume = {12},
  pages = {979-1006},
  number = {4},
  doi = {10.1137/S1052623499350013},
  owner = {LVU},
  timestamp = {2014.10.12}
}

@ARTICLE{Hullermeier-2014,
  author = {E. Hullermeier},
  title = {Learning from imprecise and fuzzy observations: Data disambiguation
	through generalized loss minimization},
  journal = {International Journal of Approximate Reasoning},
  year = {2014},
  volume = {55},
  pages = {1519-1534},
  number = {7},
  doi = {10.1016/j.ijar.2013.09.003},
  owner = {LVU},
  timestamp = {2014.03.14}
}

@ARTICLE{Irpino-Verde-2008,
  author = {A. Irpino and R. Verde},
  title = {Dynamic clustering of interval data using a {W}asserstein-based distance},
  journal = {Pattern Recognition Letters},
  year = {2008},
  volume = {29},
  pages = {1648-1658},
  number = {11},
  owner = {lev u},
  timestamp = {2016.08.21}
}

@ARTICLE{Lin-Wen-2014,
  author = {D-C. Lin and I-H. Wen},
  title = {A genetic algorithm-based virtual sample generation technique to
	improve small data set learning},
  journal = {Neurocomputing},
  year = {2014},
  volume = {143},
  pages = {222-230},
  owner = {lev u},
  timestamp = {2016.05.01}
}

@ARTICLE{Noirhomme-Fraiture-Brito-2011,
  author = {M. Noirhomme-Fraiture, P. Brito},
  title = {Far beyond the classical data models: symbolic data analysis},
  journal = {Statistical Analysis and Data Mining},
  year = {2011},
  volume = {4},
  pages = {157-170},
  number = {2},
  doi = {10.1002/sam.10112},
  owner = {LVU},
  timestamp = {2014.03.14}
}

@ARTICLE{Musdholifah-Hashim-13,
  author = {A. Musdholifah and S.Z.M. Hashim},
  title = {Cluster analysis on high-dimensional data: A comparison of density-based
	clustering algorithms},
  journal = {Australian Journal of Basic and Applied Sciences, 7(2): 380-389,
	2013},
  year = {2013},
  volume = {7},
  pages = {380-389},
  number = {2},
  owner = {LVU},
  timestamp = {2014.03.10}
}

@ARTICLE{Pedrycz-Park-Oh-2008,
  author = {W. Pedrycz and B.J. Park and S.K. Oh},
  title = {The design of granular classifiers: A study in the synergy of interval
	calculus and fuzzy sets in pattern recognition},
  journal = {Pattern Recognition},
  year = {2008},
  volume = {41},
  pages = {3720-3735},
  number = {12},
  doi = {10.1016/j.patcog.2008.06.004},
  owner = {LVU},
  timestamp = {2014.09.28}
}

@Article{Sahbi-2007,
  author  = {Hichem Sahbi},
  journal = {Neurocomputing},
  title   = {Kernel {PCA} for similarity invariant shape recognition},
  year    = {2007},
  number  = {16-18},
  pages   = {3034-3045},
  volume  = {70},
  doi     = {http://dx.doi.org/10.1016/j.neucom.2006.06.007},
}

@INCOLLECTION{Scholkopf-2001,
  author = {B. Scholkopf},
  title = {The kernel trick for distances},
  booktitle = {Advances in neural information processing systems},
  publisher = {MIT Press},
  year = {2001},
  volume = {13},
  pages = {301-307},
  address = {Cambridge, MA},
  owner = {LVU},
  timestamp = {2014.03.10}
}

@INPROCEEDINGS{Schollmeyer-Augustin-2013,
  author = {G. Schollmeyer and T. Augustin},
  title = {On sharp identification regions for regression under interval data},
  booktitle = {ISIPTA'13: Proceedings of the Eighth International Symposium on Imprecise
	Probability: Theories and Applications},
  year = {2013},
  editor = {F. Cozman and T. Den\oe{}ux and S. Destercke and T. Seidenfeld},
  pages = {285--294},
  address = {Compi\`{e}gne},
  publisher = {SIPTA}
}

@ARTICLE{Souza-Carvalho-2004,
  author = {R.M.C.R. de Souza and F. de A.T. de Carvalho},
  title = {Clustering of interval data based on city-block distances},
  journal = {Pattern Recognition Letters},
  year = {2004},
  volume = {25},
  pages = {353-365},
  doi = {10.1016/j.patrec.2003.10.016},
  owner = {LVU},
  timestamp = {2014.03.15}
}

@INBOOK{Verde-Irpino-2008,
  chapter = {Data Analysis, Machine Learning and Applications},
  pages = {705-712},
  title = {A New Interval Data Distance Based on the {W}asserstein Metric},
  publisher = {Springer},
  year = {2008},
  author = {Verde, R. and Irpino, A.},
  series = {Studies in Classification, Data Analysis, and Knowledge Organization},
  address = {Berlin, Heidelberg},
  booktitle = {Data Analysis, Machine Learning and Applications: Proceedings of
	the 31st Annual Conference of the Gesellschaft f{\"u}r Klassifikation
	e.V., Albert-Ludwigs-Universit{\"a}t Freiburg, March 7--9, 2007},
  doi = {10.1007/978-3-540-78246-9_83},
  isbn = {978-3-540-78246-9},
  owner = {lev u},
  timestamp = {2016.08.21},
  url = {http://dx.doi.org/10.1007/978-3-540-78246-9_83}
}

@ARTICLE{Wang-Pardalos-2014,
  author = {Wang, X. and Pardalos, P.M.},
  title = {A survey of support vector machines with uncertainties},
  journal = {Annals of Data Science},
  year = {2014},
  volume = {1},
  pages = {293-309},
  number = {3-4},
  abstract = {Support Vector Machines (SVM) is one of the well known supervised
	classes of learning algorithms. SVM have wide applications to many
	fields in recent years and also many algorithmic and modeling variations.
	Basic SVM models are dealing with the situation where the exact values
	of the data points are known. This paper presents a survey of SVM
	when the data points are uncertain. When a direct model cannot guarantee
	a generally good performance on the uncertainty set, robust optimization
	is introduced to deal with the worst case scenario and still guarantee
	an optimal performance. The data uncertainty could be an additive
	noise which is bounded by norm, where some efficient linear programming
	models are presented under certain conditions; or could be intervals
	with support and extremum values; or a more general case of polyhedral
	uncertainties with formulations presented. Another field of the uncertainty
	analysis is chance constrained SVM which is used to ensure the small
	probability of misclassification for the uncertain data. The multivariate
	Chebyshev inequality and Bernstein bounding schemes have been used
	to transform the chance constraints through robust optimization.
	The Chebyshev based model employs moment information of the uncertain
	training points. The Bernstein bounds can be less conservative than
	the Chebyshev bounds since it employs both support and moment information,
	but it also makes a strong assumption that all the elements in the
	data set are independent.},
  doi = {10.1007/s40745-014-0022-8},
  issn = {2198-5804},
  language = {English},
  owner = {lev u},
  publisher = {Springer Berlin Heidelberg},
  timestamp = {2015.09.26},
  url = {http://dx.doi.org/10.1007/s40745-014-0022-8}
}

@INPROCEEDINGS{Wiencierz-Cattaneo-2015,
  author = {A. Wiencierz and M.E.G.V. Cattaneo},
  title = {On the validity of minimin and minimax methods for support vector
	regression with interval data},
  booktitle = {9th International Symposium on Imprecise Probability: Theories and
	Applications},
  year = {2015},
  pages = {325-332},
  address = {Pescara, Italy},
  publisher = {SIPTA},
  owner = {lev u},
  timestamp = {2015.09.07},
  url = {http://www.sipta.org/isipta15/pdf/isipta15proceedings.pdf}
}

@INPROCEEDINGS{Xie-Wei-Liu-2006,
  author = {Hong Xie and Jiang-Ping Wei and He-Li Liu},
  title = {Linear Programming Regressive Support Vector Machine},
  booktitle = {Machine Learning and Cybernetics, 2006 International Conference on},
  year = {2006},
  pages = {2196-2199},
  month = {Aug},
  abstract = {Based on the analysis of the general norm in structure risk to control
	model complexity for regressive problem, two kinds of linear programming
	support vector machine corresponding to l1-norm and linfin-norm are
	presented including linear and nonlinear SVMs. A numerical experiment
	has been done for these two kinds of linear programming support vector
	machines and classic support vector machine by artificial data. Simulation
	results show that the generalization performance of this two kind
	linear programming SVM is similar to classic one, l1-SVM has less
	number of support vectors and faster learning speed, and learning
	result is not sensitive to learning parameters},
  doi = {10.1109/ICMLC.2006.258619},
  keywords = {learning (artificial intelligence);linear programming;regression analysis;support
	vector machines;SVM;artificial data;linear programming regressive
	support vector machine;model complexity;regressive problem;Cybernetics;Educational
	institutions;Electronic mail;Information technology;Linear programming;Machine
	learning;Matrix decomposition;Probability distribution;Quadratic
	programming;Statistical learning;Support vector machines;Linear programming;Statistical
	learning theory;Support vector machines;VC dimension}
}

@PHDTHESIS{Xu-PhD-2010,
  author = {W. Xu},
  title = {Symbolic Data Analysis: Interval-valued Data Regression},
  school = {University of Georgia},
  year = {2010},
  type = {PhD thesis},
  owner = {lev u},
  timestamp = {2015.10.31}
}

@ARTICLE{Zhou-Zhang-Jiao-02,
  author = {W. Zhou and L. Zhang and L. Jiao},
  title = {Linear programming support vector machines},
  journal = {Pattern Recognition},
  year = {2002},
  volume = {35},
  pages = {2927-2936},
  number = {12},
  doi = {10.1016/S0031-3203(01)00210-2},
  owner = {LVU},
  timestamp = {2014.05.01}
}

@Article{Shevchenko-Peters-13,
  author  = {P.V. Shevchenko and G. Peters},
  journal = {Journal of Governance and Regulation},
  title   = {Loss Distribution Approach for Operational Risk Capital Modelling under Basel II: Combining Different Data Sources for Risk Estimation},
  year    = {2013},
  number  = {3},
  pages   = {33--57},
  volume  = {2},
}

@Comment{jabref-meta: databaseType:bibtex;}
