% Encoding: windows-1251


@Article{Bondell-Reich-2008,
  Title                    = {Simultaneous regression shrinkage, variable selection and clustering of predictors with {OSCAR}},
  Author                   = {H.D. Bondell and B.J. Reich},
  Journal                  = {Biometrics},
  Year                     = {2008},
  Number                   = {1},
  Pages                    = {115-123},
  Volume                   = {64},
  Owner                    = {LVU},
  Timestamp                = {2015.02.11}
}

@Book{Buhlmann-Geer-2011,
  Title                    = {Statistics for High-Dimensional Data: Methods, Theory and Applications},
  Author                   = {P. Buhlmann and S. van de Geer},
  Publisher                = {Springer},
  Year                     = {2011},
  Address                  = {Berlin Heidelberg},
  Series                   = {Springer Series in Statistics},
  Owner                    = {LVU},
  Pages                    = {558},
  Timestamp                = {2013.11.12}
}

@Article{Buhlmann-Hothorn-2007,
  Title                    = {Boosting Algorithms: Regularization, Prediction and Model Fitting},
  Author                   = {P. Buhlmann and T. Hothorn},
  Journal                  = {Statistical Science},
  Year                     = {2007},
  Number                   = {4},
  Pages                    = {477-505},
  Volume                   = {22},
  Abstract                 = {We present a statistical perspective on boosting. Special emphasis is given to estimating potentially complex parametric or nonparametric models, including generalized linear and additive models as well as regression models for survival analysis. Concepts of degrees of freedom and corresponding Akaike or Bayesian information criteria, particularly useful for regularization and variable selection in highdimensional covariate spaces, are discussed as well.
The practical aspects of boosting procedures for fitting statistical models are illustrated by means of the dedicated open-source software package mboost. This package implements functions which can be used for model fitting, prediction and variable selection. It is flexible, allowing for the implementation of new boosting algorithms optimizing user-specified loss functions.},
  DOI                      = {10.1214/07-STS242},
  Owner                    = {LVU},
  Timestamp                = {2013.11.02}
}

@Article{Buhlmann-Hothorn-2010,
  Title                    = {Twin boosting: Improved feature selection and prediction},
  Author                   = {P. Buhlmann and T. Hothorn},
  Journal                  = {Statistics and Computing},
  Year                     = {2010},
  Number                   = {2},
  Pages                    = {119-138},
  Volume                   = {20},
  Abstract                 = {We propose Twin Boosting which has much better feature selection behavior than boosting, particularly with respect to reducing the number of false positives (falsely selected features). In addition, for cases with a few important effective and many noise features, Twin Boosting also substantially improves the predictive accuracy of boosting. Twin Boosting is as general and generic as (gradient-based) boosting. It can be used with general weak learners and in a wide variety of situations, including generalized regression, classification or survival modeling. Furthermore, it is computationally feasible for large problems with potentially many more features than observed samples. Finally, for the special case of orthonormal linear models, we prove equivalence of Twin Boosting to the adaptive Lasso which provides some theoretical aspects on feature selection with Twin Boosting.},
  DOI                      = {10.1007/s11222-009-9148-5},
  Owner                    = {LVU},
  Timestamp                = {2013.11.02}
}

@Article{Buhlmann-Meier-2008,
  Title                    = {Discussion of ``{O}ne-step sparse estimates in nonconcave penalized likelihood models''},
  Author                   = {P. Buhlmann and L. Meier},
  Journal                  = {Annals of Statistics},
  Year                     = {2008},
  Pages                    = {1534-1541},
  Volume                   = {36},
  Owner                    = {lev u},
  Timestamp                = {2016.05.03}
}

@Article{Chen-Tang-Gao-Shi-14,
  Title                    = {New Robust Variable Selection Methods for Linear Regression Models},
  Author                   = {Chen, Ziqi and Tang, Man-Lai and Gao, Wei and Shi, Ning-Zhong},
  Journal                  = {Scandinavian Journal of Statistics},
  Year                     = {2014},
  Abstract                 = {Motivated by an entropy inequality, we propose for the first time a penalized profile likelihood method for simultaneously selecting significant variables and estimating unknown coefficients in multiple linear regression models in this article. The new method is robust to outliers or errors with heavy tails and works well even for error with infinite variance. Our proposed approach outperforms the adaptive lasso in both theory and practice. It is observed from the simulation studies that (i) the new approach possesses higher probability of correctly selecting the exact model than the least absolute deviation lasso and the adaptively penalized composite quantile regression approach and (ii) exact model selection via our proposed approach is robust regardless of the error distribution. An application to a real dataset is also provided.},
  DOI                      = {10.1111/sjos.12057},
  ISSN                     = {1467-9469},
  Keywords                 = {adaptive lasso, entropy inequality, oracle properties, penalized profile likelihood, profile likelihood, robustness, variable selection},
  Owner                    = {LVU},
  Timestamp                = {2014.01.25}
}

@Article{Friedman-Hastie-Tibshirani-09,
  Title                    = {Regularization Paths for Generalized Linear Models via Coordinate Descent},
  Author                   = {J.H. Friedman and T. Hastie and R. Tibshirani},
  Journal                  = {Journal of Statistical Software},
  Year                     = {2010},
  Number                   = {1},
  Pages                    = {1-22},
  Volume                   = {33}
}

@Article{Madsen-Browning-2009,
  Title                    = {A groupwise association test for rare mutations using a weighted sum statistic},
  Author                   = {B.E. Madsen and S.R. Browning},
  Journal                  = {PLoS genetics},
  Year                     = {2009},
  Number                   = {2},
  Pages                    = {e1000384},
  Volume                   = {5},
  DOI                      = {10.1371/journal.pgen.1000384},
  Owner                    = {LVU},
  Timestamp                = {2013.11.12}
}

@Article{Petry-Tutz-2012,
  Title                    = {Shrinkage and variable selection by polytopes},
  Author                   = {S. Petry and G. Tutz},
  Journal                  = {Journal of Statistical Planning and Inference},
  Year                     = {2012},
  Number                   = {1},
  Pages                    = {48-64},
  Volume                   = {142}
}

@Article{Tibshirani-1996,
  Title                    = {Regression shrinkage and selection via the {L}asso},
  Author                   = {R. Tibshirani},
  Journal                  = {Journal of the Royal Statistical Society. Series B (Methodological)},
  Year                     = {1996},
  Number                   = {1},
  Pages                    = {267-288},
  Volume                   = {58},
  Owner                    = {LVU},
  Timestamp                = {2013.11.12}
}

@Article{Tutz-Ulbricht-2009,
  Title                    = {Penalized regression with correlation-based penalty},
  Author                   = {G. Tutz and J. Ulbricht},
  Journal                  = {Statistics and Computing},
  Year                     = {2009},
  Number                   = {3},
  Pages                    = {239-253},
  Volume                   = {19},
  Owner                    = {LVU},
  Timestamp                = {2013.11.12}
}

@Article{Wang-Cheng-Liu-Zhu-2014,
  Title                    = {A robust elastic net approach for feature learning},
  Author                   = {L. Wang and H. Cheng and Z. Liu and C. Zhu},
  Journal                  = {Journal of Visual Communication and Image Representation},
  Year                     = {2014},
  Number                   = {2},
  Pages                    = {313-321},
  Volume                   = {25},
  Owner                    = {lev u},
  Timestamp                = {2016.05.03}
}

@Article{Xiao-Xu-2015,
  Title                    = {Multi-step adaptive elastic-net: reducing false positives in high-dimensional variable selection},
  Author                   = {N. Xiao and Q.-S. Xu},
  Journal                  = {Journal of Statistical Computation and Simulation},
  Year                     = {2015},
  Number                   = {18},
  Pages                    = {3755-3765},
  Volume                   = {85},
  Owner                    = {lev u},
  Timestamp                = {2016.05.03}
}

@InProceedings{Zhou-2011,
  Title                    = {Penalized regression for genome-wide association screening of sequence data},
  Author                   = {H. Zhou and D.H. Alexander and M.E. Sehl and J.S. Sinsheimer and K. Lange},
  Booktitle                = {Pacific Symposium on Biocomputing},
  Year                     = {2011},
  Pages                    = {106-117},
  Publisher                = {World Scientific Publishing},
  Owner                    = {LVU},
  Timestamp                = {2013.11.12}
}

@Article{Zou-Zhang-2009,
  Title                    = {On the adaptive elastic-net with a diverging number of parameters},
  Author                   = {B.H. Zou and H.H. Zhang},
  Journal                  = {The Annals of Statistics},
  Year                     = {2009},
  Number                   = {4},
  Pages                    = {1733-1751},
  Volume                   = {37},
  Owner                    = {lev u},
  Timestamp                = {2016.05.03}
}

@Article{Zou-2006,
  Title                    = {The adaptive {L}asso and its oracle properties},
  Author                   = {H. Zou},
  Journal                  = {Journal of the American Statistical Association},
  Year                     = {2006},
  Number                   = {476},
  Pages                    = {1418-1429},
  Volume                   = {101},
  DOI                      = {10.1198/016214506000000735},
  Owner                    = {LVU},
  Timestamp                = {2013.11.12}
}

@Article{Zou-Hastie-2005,
  Title                    = {Regularization and variable selection via the elastic net},
  Author                   = {H. Zou and T. Hastie},
  Journal                  = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  Year                     = {2005},
  Number                   = {2},
  Pages                    = {301-320},
  Volume                   = {67},
  Owner                    = {LVU},
  Timestamp                = {2013.11.12}
}

@Book{Hastie-Tibshirani-1990,
  author    = {T. Hastie and R. Tibshirani},
  publisher = {CRC press},
  title     = {Generalized additive models},
  year      = {1990},
  volume    = {43},
}

@Article{Petersen-etal-16,
  author  = {A. Petersen and D. Witten and N. Simon},
  journal = {Journal of Computational and Graphical Statistics},
  title   = {Fused lasso additive model},
  year    = {2016},
  number  = {4},
  pages   = {1005--1025},
  volume  = {25},
}

@Comment{jabref-meta: databaseType:bibtex;}
