% This file was created with JabRef 2.10.
% Encoding: Cp1251


@InCollection{Burduk-2009,
  Title                    = {Probability error in global optimal hierarchical classifier with intuitionistic fuzzy observations},
  Author                   = {R. Burduk},
  Booktitle                = {Hybrid Artificial Intelligence Systems},
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2009},
  Editor                   = {Corchado, Emilio and Wu, Xindong and Oja, Erkki and Herrero, √Ålvaro and Baruque, Bruno},
  Pages                    = {533-540},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {5572},

  Abstract                 = {The paper considers the problem of classification error in pattern recognition. This model of classification is primarily based on the Bayes rule and secondarily on the notion of intuitionistic fuzzy sets. A probability of misclassifications is derived for a classifier under the assumption that the features are class-conditionally statistically independent, and we have intuitionistic fuzzy information on object features instead of exact information. Additionally, we consider the global optimal hierarchical classifier.}
}

@Article{Burduk-2010,
  Title                    = {Classification error in {B}ayes multistage recognition task with fuzzy observations},
  Author                   = {R. Burduk},
  Journal                  = {Pattern Analysis \& Applications},
  Year                     = {2010},
  Pages                    = {85-91},
  Volume                   = {13},

  Abstract                 = {The paper considers the problem of classification error in multistage pattern recognition. This model of classification is based primarily on the Bayes rule and secondarily on the notion of fuzzy numbers. In adopting a probability-fuzzy model two concepts of hierarchical rules are proposed. In the first approach the local criterion that denote the probabilities of misclassification for particular nodes of a tree is considered. In the second approach the global optimal strategy that minimises the mean probability of misclassification on the whole multistage recognition process is considered. A probability of misclassifications is derived for a multiclass hierarchical classifier under the assumption that the features at different nodes of the tree are class-conditionally statistically independent, and we have fuzzy information on object features instead of exact information. Numerical example of this difference concludes the work.},
  Issue                    = {1}
}

@Article{Hao-2008,
  Title                    = {Fuzzy one-class support vector machines},
  Author                   = {P.-Y. Hao},
  Journal                  = {Fuzzy Sets and Systems},
  Year                     = {2008},
  Pages                    = {2317-2336},
  Volume                   = {159},

  Owner                    = {LVU},
  Timestamp                = {2012.04.07}
}

@InCollection{Hao-Chi-Yan-Yue-2007,
  Title                    = {An improved fuzzy support vector machine for credit rating},
  Author                   = {Y. Hao and Z. Chi and D. Yan and X. Yue},
  Booktitle                = {Network and Parallel Computing},
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2007},
  Editor                   = {Li, Keqiu and Jesshope, Chris and Jin, Hai and Gaudiot, Jean-Luc},
  Pages                    = {495-505},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {4672}
}

@Article{Hong-Hwang-2003,
  Title                    = {Support vector fuzzy regression machines},
  Author                   = {D.H. Hong and C. Hwang},
  Journal                  = {Fuzzy Sets and Systems},
  Year                     = {2003},
  Pages                    = {271-281},
  Volume                   = {138},

  Owner                    = {LVU},
  Timestamp                = {2012.04.07}
}

@Article{Jiang-Yi-Lv-2006,
  Title                    = {Fuzzy {SVM} with a new fuzzy membership function},
  Author                   = {X. Jiang and Z. Yi and J.C. Lv},
  Journal                  = {Neural Computing \& Applications},
  Year                     = {2006},
  Number                   = {3},
  Pages                    = {268-276},
  Volume                   = {15},

  Abstract                 = {It is known that with a proper fuzzy membership function, a fuzzy support vector machine can effectively reduce the effects of outliers when solving the classification problem. In this paper, a new fuzzy membership function is proposed to the nonlinear fuzzy support vector machine. The fuzzy membership is calculated in the feature space and is represented by kernels. This method gives good performance on reducing the effects of outliers and significantly improves the classification accuracy and generalization.}
}

@InCollection{Li-Fang-2003,
  Title                    = {Application of fuzzy support vector machines in short-term load forecasting},
  Author                   = {Y. Li and T. Fang},
  Booktitle                = {Rough Sets, Fuzzy Sets, Data Mining, and Granular Computing},
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2003},
  Editor                   = {Wang, Guoyin and Liu, Qing and Yao, Yiyu and Skowron, Andrzej},
  Pages                    = {571-571},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {2639},

  Abstract                 = {A new method using Fuzzy Support Vector Machines (FSVM) is presented for Short-Term Load Forecasting (STLF). In many regression problems, the effects of the training points are different. It is often that some training points are more important than others. In FSVM, we apply a fuzzy membership to each input point such that different input points can make different contributions to the learning of decision surface. The results of experiment indicate that FSVM is effective in improving the accuracy of STLF.}
}

@InCollection{Lin-Wang-05,
  Title                    = {Fuzzy support vector machines with automatic membership setting},
  Author                   = {C.-F. Lin and S.-D. Wang},
  Booktitle                = {Support Vector Machines: Theory and Applications},
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2005},
  Editor                   = {Wang, Lipo},
  Pages                    = {629-629},
  Series                   = {Studies in Fuzziness and Soft Computing},
  Volume                   = {177},

  Abstract                 = {Support vector machines like other classification approaches aim to learn the decision surface from the input points for classification problems or regression problems. In many applications, each input points may be associated with different weightings to reflect their relative strengths to conform to the decision surface. In our previous research, we applied a fuzzy membership to each input point and reformulate the support vector machines to be fuzzy support vector machines (FSVMs) such that different input points can make different contributions to the learning of the decision surface.}
}

@Article{Lin-Wang-04,
  Title                    = {Training algorithms for fuzzy support vector machines with noisy data},
  Author                   = {C.-F. Lin and S.-D. Wang},
  Journal                  = {Pattern Recognition Letters},
  Year                     = {2004},
  Number                   = {14},
  Pages                    = {464-471},
  Volume                   = {25},

  Owner                    = {LVU},
  Timestamp                = {2012.04.07}
}

@Article{Lin-Wang-02,
  Title                    = {Fuzzy support vector machines},
  Author                   = {C.-F. Lin and S.-D. Wang},
  Journal                  = {IEEE Transactions on Neural Networks},
  Year                     = {2002},
  Number                   = {2},
  Pages                    = {464-471},
  Volume                   = {13},

  Owner                    = {LVU},
  Timestamp                = {2012.04.07}
}

@Article{Otto-Bandemer-1986,
  Title                    = {Pattern recognition based on fuzzy observations for spectroscopic quality control and chromatographic fingerprinting},
  Author                   = {M. Otto and H. Bandemer},
  Journal                  = {Analytica Chimica Acta},
  Year                     = {1986},
  Pages                    = {21-31},
  Volume                   = {184},

  Abstract                 = {The quality of multicomponent samples from one or several groups of samples can be monitored by a pattern recognition method. The method is based on profiles of sample quality, which are obtained by means of a multicomponent analytical technique (e.g., ultraviolet spectroscopy or chromatography), and data reduction is done with the aid of fuzzy set theory. The advantages of the method in cases of overlapping and non-additive signals are outlined for quality control of analgesic tablets by ultraviolet spectroscopy. Its performance in the case of highly uncertain data patterns is demonstrated for classification of protein samples by chromatography.}
}

@Article{Tang-2011,
  Title                    = {Fuzzy {SVM} with a new fuzzy membership function to solve the two-class problems},
  Author                   = {W.M. Tang},
  Journal                  = {Neural Processing Letters},
  Year                     = {2011},
  Pages                    = {209-219},
  Volume                   = {34},

  Abstract                 = {In dealing with the Two-Class classification problems, the traditional support vector machine (SVM) often cannot achieve good classification accuracy when outliers exist in the training data set. The fuzzy support vector machine (FSVM) can resolve this problem with an appropriate fuzzy membership for each data point. The effect of the outliers can be effectively reduced when the classification problem is solved. In this paper, a new fuzzy membership function is employed in the linear and nonlinear fuzzy support vector machine respectively. The fuzzy membership is calculated based on the structural information of two classes in the input space and in the feature space. This method can distinguish the support vectors and the outliers effectively. Experimental results show that this approach contributes greatly to the reduction of the effect of the outliers and significantly improves the classification accuracy and generalization.},
  Issue                    = {3}
}

@comment{jabref-meta: selector_keywords:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

